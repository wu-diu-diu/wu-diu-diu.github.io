<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><meta name="author" content="武丢丢"><meta name="renderer" content="webkit"><meta name="copyright" content="武丢丢"><meta name="keywords" content="武丢丢"><meta name="description" content="null"><meta name="Cache-Control" content="no-cache"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>RAG-langchain · Punchy's Blog</title><link rel="stylesheet" href="/css/style.css?v=2018.7.9"><link rel="stylesheet" href="/css/animation.css?v=2018.7.9"><link rel="icon" href="/img/assets/favicon.ico"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.6"><!-- scripts--><script>(function( w ){
  "use strict";
  // rel=preload support test
  if( !w.loadCSS ){
    w.loadCSS = function(){};
  }
  // define on the loadCSS obj
  var rp = loadCSS.relpreload = {};
  // rel=preload feature support test
  // runs once and returns a function for compat purposes
  rp.support = (function(){
    var ret;
    try {
      ret = w.document.createElement( "link" ).relList.supports( "preload" );
    } catch (e) {
      ret = false;
    }
    return function(){
      return ret;
    };
  })();

  // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
  // then change that media back to its intended value on load
  rp.bindMediaToggle = function( link ){
    // remember existing media attr for ultimate state, or default to 'all'
    var finalMedia = link.media || "all";

    function enableStylesheet(){
      link.media = finalMedia;
    }

    // bind load handlers to enable media
    if( link.addEventListener ){
      link.addEventListener( "load", enableStylesheet );
    } else if( link.attachEvent ){
      link.attachEvent( "onload", enableStylesheet );
    }

    // Set rel and non-applicable media type to start an async request
    // note: timeout allows this to happen async to let rendering continue in IE
    setTimeout(function(){
      link.rel = "stylesheet";
      link.media = "only x";
    });
    // also enable media after 3 seconds,
    // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
    setTimeout( enableStylesheet, 3000 );
  };

  // loop through link elements in DOM
  rp.poly = function(){
    // double check this to prevent external calls from running
    if( rp.support() ){
      return;
    }
    var links = w.document.getElementsByTagName( "link" );
    for( var i = 0; i < links.length; i++ ){
      var link = links[ i ];
      // qualify links to those with rel=preload and as=style attrs
      if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
        // prevent rerunning on link
        link.setAttribute( "data-loadcss", true );
        // bind listeners to toggle media back
        rp.bindMediaToggle( link );
      }
    }
  };

  // if unsupported, run the polyfill
  if( !rp.support() ){
    // run once at least
    rp.poly();

    // rerun poly on an interval until onload
    var run = w.setInterval( rp.poly, 500 );
    if( w.addEventListener ){
      w.addEventListener( "load", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    } else if( w.attachEvent ){
      w.attachEvent( "onload", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    }
  }


  // commonjs
  if( typeof exports !== "undefined" ){
    exports.loadCSS = loadCSS;
  }
  else {
    w.loadCSS = loadCSS;
  }
}( typeof global !== "undefined" ? global : this ) );</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" defer></script><script src="/js/main.js?v=2018.7.9" defer></script><!-- fancybox--><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script><!-- busuanzi--><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 7.1.1"></head><body><section class="profile-close" id="cxo-profile"><div class="profile-avatar"><i class="fa fa-caret-left"></i><img src="/img/assets/me.png"></div><!--.profile-saying
  i.fa.fa-comment
  .saying--><div class="cxo-profile-inner"><div class="profile-name">punchy</div><div class="profile-signature">Stay foolish Stay hungry</div><div class="read-progress"></div></div></section><header id="cxo-intro" style="height: 70vh;background-image: url(/img/intro/index-bg.png);"><nav id="cxo-intro-nav"><section><div class="intro-nav-title"><a href="/">Wudiudiu's Blog</a></div><div class="intro-nav-label-box"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div><i class="fa fa-bars intro-nav-menu"><div class="intro-nav-drop"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div></i><div class="clear"></div></section></nav><h1 class="post-title">RAG-langchain</h1><div class="post-intros"><div class="post-intro-meta"><span class="post-intro-time"><i class="post-intro-calendar fa fa-calendar"></i><span>2025-04-07</span></span><span class="post-intro-tags"><a class="intro-tag fa fa-tag" href="javascript:void(0)" date-tags="LLM"> LLM</a></span></div></div></header><article class="cxo-up" id="cxo-content-outer"><section id="cxo-content-inner"><article class="article-entry" id="post"><h1 id="RAG学习"><a href="#RAG学习" class="headerlink" title="RAG学习"></a>RAG学习</h1><h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>我们需要利用给定的数据形成知识库，数据的类型多种多样，langchain提供了很多工具来帮助我们加载和处理数据。比如加载PDF文档。</p>
<h3 id="从某一个目录下加载所有PDF文档"><a href="#从某一个目录下加载所有PDF文档" class="headerlink" title="从某一个目录下加载所有PDF文档"></a>从某一个目录下加载所有PDF文档</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> PyPDFDirectoryLoader</span><br><span class="line"></span><br><span class="line">DATA_PATH = <span class="string">&quot;data&quot;</span></span><br><span class="line"></span><br><span class="line">document_loader = PyPDFDirectoryLoader(DATA_PATH)</span><br><span class="line">document = document_loader.load()</span><br></pre></td></tr></table></figure>
<p>上面返回的document是一个列表，其中的每一个元素是一个<code>Document</code>类，查看其属性如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">document[<span class="number">0</span>].__dict__</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;id&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">&#x27;metadata&#x27;</span>: &#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;Acrobat Distiller 9.5.5 (Macintosh)&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;QuarkXPress 9.5.3.1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2015-03-09T10:16:51-07:00&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;cyrille&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;gts_pdfxversion&#x27;</span>: <span class="string">&#x27;PDF/X-3:2002&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2015-05-18T11:25:26-07:00&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;[T2R] rules EN reprint 2015_TTR2 rules US&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;trapped&#x27;</span>: <span class="string">&#x27;/False&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;data/ticket_to_ride.pdf&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;total_pages&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">  <span class="string">&#x27;page&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;1&#x27;</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;page_content&#x27;</span>: <span class="string">&#x27;O\nn a blustery autumn evening five old friends...&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;Document&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>主要有四个属性，id，metadata, page_content, type。本例中一共有两个PDF文件，共12页，document这个列表的长度也为12。所以该方法是对每页PDF提取文字，构建一个Document类并返回。</p>
<h3 id="文档拆分"><a href="#文档拆分" class="headerlink" title="文档拆分"></a>文档拆分</h3><p>我们从PDF文件中提取出文本内容后，需要将文本拆分成句子再变成向量。文本到句子这个过程就需要使用文本切分工具，怎么切分，切多大，两个相邻切分块之前的重合文本数量是多少这些都会影响我们最终的检索效果。</p>
<p><code>RecursiveCharacterTextSplitter</code>是一个用于将长文本分割成较小块的工具，通常用于自然语言处理任务中，特别是在处理嵌入和向量数据库时。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">        chunk_size=<span class="number">800</span>,  <span class="comment">## 每个文本块的最大字符数</span></span><br><span class="line">        chunk_overlap=<span class="number">80</span>,  <span class="comment">## 相邻文本块之间的重叠字符数，用于保持上下文的连贯性</span></span><br><span class="line">        length_function=<span class="built_in">len</span>, <span class="comment">## 用于计算文本长度的函数，默认是 len，即字符数。</span></span><br><span class="line">        is_separator_regex=<span class="literal">False</span>,  <span class="comment">## 是否使用正则表达式来识别分隔符，这里使用默认的分隔符比如空格来切分字符</span></span><br><span class="line">    )</span><br><span class="line"><span class="comment">## split_documents方法接受document类作为输入</span></span><br><span class="line"><span class="comment">## 返回还是一个包含document</span></span><br><span class="line">chunk = text_splitter.split_documents(documents)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 当然，还可以接受一般的字符串作为输入进行切分</span></span><br><span class="line">text = <span class="string">&quot;我们从PDF文件中提取出文本内容后，需要将文本拆分成句子再变成向量。文本到句子这个过程就需要使用文本切分工具，怎么切分，切多大，两个相邻切分块之前的重合文本数量是多少这些都会影响我们最终的检索效果。&quot;</span></span><br><span class="line"></span><br><span class="line">chunks = text_splitter.split_text(text)</span><br></pre></td></tr></table></figure>
<p>split_documents方法返回的还是一个包含document元素的列表，只不过将原来的内容按照要求分隔的更小了。其属性包含如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">chunk[<span class="number">0</span>].__dict__</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;id&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">&#x27;metadata&#x27;</span>: &#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;Acrobat Distiller 9.5.5 (Macintosh)&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;QuarkXPress 9.5.3.1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2015-03-09T10:16:51-07:00&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;cyrille&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;gts_pdfxversion&#x27;</span>: <span class="string">&#x27;PDF/X-3:2002&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2015-05-18T11:25:26-07:00&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;[T2R] rules EN reprint 2015_TTR2 rules US&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;trapped&#x27;</span>: <span class="string">&#x27;/False&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;data/ticket_to_ride.pdf&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;total_pages&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">  <span class="string">&#x27;page&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;1&#x27;</span>&#125;,</span><br><span class="line"> <span class="string">&#x27;page_content&#x27;</span>: <span class="string">&#x27;O\nn a blustery autumn evening five old friends met in the backroom of one of the city’s oldest and most private clubs. Each had\ntraveled a long distance — from all corners of the world — to meet on this very specific day… October 2, 1900 — 28 years to the\nday that the London eccentric, Phileas Fogg accepted and then won a £20,000 bet that he could travel Around the World in 80 Days . \nWhen the story of Fogg’s triumphant journey filled all the newspapers of the day, the five attended University together. Inspired by\nhis impetuous gamble, and a few pints from the local pub, the group commemorated his circumnavigation with a more modest excur-\nsion and wager – a bottle of good claret to the first to make it to Le Procope in Paris.&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;Document&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<h3 id="为chunk添加id"><a href="#为chunk添加id" class="headerlink" title="为chunk添加id"></a>为chunk添加id</h3><p>为了提高RAG的可信度，我们需要LLM在利用RAG回答完问题后，能给出具体参考了哪个文件的哪一个段落。那么就需要我们为每一个chunk添加一个能显示上述信息的id。函数如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_chunk_ids</span>(<span class="params">chunks</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># This will create IDs like &quot;data/monopoly.pdf:6:2&quot; 表示monopoly这个pdf的第六页中的第3个chunk</span></span><br><span class="line">    <span class="comment"># Page Source : Page Number : Chunk Index</span></span><br><span class="line"></span><br><span class="line">    last_page_id = <span class="literal">None</span></span><br><span class="line">    current_chunk_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:</span><br><span class="line">        source = chunk.metadata.get(<span class="string">&quot;source&quot;</span>)</span><br><span class="line">        page = chunk.metadata.get(<span class="string">&quot;page&quot;</span>)</span><br><span class="line">        current_page_id = <span class="string">f&quot;<span class="subst">&#123;source&#125;</span>:<span class="subst">&#123;page&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># If the page ID is the same as the last one, increment the index.</span></span><br><span class="line">        <span class="keyword">if</span> current_page_id == last_page_id:</span><br><span class="line">            current_chunk_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            current_chunk_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the chunk ID.</span></span><br><span class="line">        chunk_id = <span class="string">f&quot;<span class="subst">&#123;current_page_id&#125;</span>:<span class="subst">&#123;current_chunk_index&#125;</span>&quot;</span></span><br><span class="line">        last_page_id = current_page_id</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Add it to the page meta-data.</span></span><br><span class="line">        <span class="comment">## 在metadata字典中添加一个id键</span></span><br><span class="line">        chunk.metadata[<span class="string">&quot;id&quot;</span>] = chunk_id</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> chunks</span><br></pre></td></tr></table></figure>
<p>该函数的作用本质上是将chunk自带的source和page信息抽取出来，加一个if来判断当前chunk和上一个chunk是否属于同一页内容，属于则当前chunk的id为上一下chunk的id加1，不属于则当前chunk的id为0，表示新的一页内容。所以每个chunk的metadata中都添加了一个id键，其属性为:<code>&quot;data/monopoly.pdf:6:2&quot;</code>记录了该chunk来自哪篇文件，哪一页的第几个chunk。</p>
<h3 id="添加到向量数据库中"><a href="#添加到向量数据库中" class="headerlink" title="添加到向量数据库中"></a>添加到向量数据库中</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/665715823">向量数据库Chroma极简教程</a></p>
<p>LLM 的核心支持技术之一是向量嵌入。虽然计算机不能直接理解文本，但我们可以将文本表示成向量以供计算机去理解和计算。在transformer中，模型就是直接处理每个token的语义向量来理解句子的意思。注意力机制相当于LLM的大脑，我们输入文本，LLM经过思考后回答。但是LLM的知识是有限的，有时候是过时的。如果我们想要LLM对于自己不熟悉的内容也能给出回答，那么就需要给LLM一个字典，这个字典用来存储一些LLM在训练中没有见过的知识。这个字典就是向量数据库。</p>
<p>向量存储是专门为有效地存储和检索向量嵌入而设计的数据库。之所以需要它们，是因为像 SQL 这样的传统数据库没有针对存储和查询大型向量数据进行优化。向量存储可以使用相似性算法对相似的向量进行索引和快速搜索。它允许应用程序在给定目标向量查询的情况下查找相关向量。</p>
<p><code>ChromaDB</code>是一款开源的矢量存储数据库，用于存储和检索矢量嵌入。它的主要用途是保存嵌入和元数据，以便以后由大型语言模型使用。此外，它还可用于文本数据的语义搜索引擎。</p>
<p>在langchain中，我们可以这样使用：第一个参数为存储的数据库的集合命名，第二个参数为本地存储的路径，第三个为embedding的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">db = Chroma(</span><br><span class="line">        collection_name=<span class="string">&quot;example_collection&quot;</span>,</span><br><span class="line">        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>以上代码初始化一个向量数据库，接下来我们可以使用<code>add_documents</code>方法来将上面的chunks都添加到向量数据库中，该方法会自动将文档即document中的内容转化为嵌入向量并存储。参数如下：</p>
<ul>
<li>documents: 要添加的文档列表</li>
<li>metadatas: 与文档关联的元数据列表，用于存储额外信息并支持过滤。</li>
<li>ids: 文档的唯一标识符列表。</li>
<li>embeddings: 如果提供，Chroma 将存储这些嵌入向量，而不会自行计算。</li>
</ul>
<p>示例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> uuid <span class="keyword">import</span> uuid4</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line">document_1 = Document(</span><br><span class="line">    page_content=<span class="string">&quot;I had chocolate chip pancakes and scrambled eggs for breakfast this morning.&quot;</span>,</span><br><span class="line">    metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;tweet&quot;</span>&#125;,</span><br><span class="line">    <span class="built_in">id</span>=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">document_2 = Document(</span><br><span class="line">    page_content=<span class="string">&quot;The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.&quot;</span>,</span><br><span class="line">    metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;news&quot;</span>&#125;,</span><br><span class="line">    <span class="built_in">id</span>=<span class="number">2</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">documents = [document_1, document_2]</span><br><span class="line"></span><br><span class="line">uuids = [<span class="built_in">str</span>(uuid4()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(documents))]</span><br><span class="line"></span><br><span class="line">vector_store.add_documents(documents=documents, ids=uuids)</span><br></pre></td></tr></table></figure>
<p>其中uuid是文档对应的唯一标识符，像这样:<code>f22ed484-6db3-4b76-adb1-18a777426cd6</code>,在代码中使用 uuid4 为每个文档生成一个唯一的 ID，确保了文档的唯一性和可识别性。这在处理大量文档或分布式系统时尤为重要。从上面的代码中可以看到chunk在创建的时候是没有id的，<code>&#39;id&#39;: None,</code>。这里我们可以用前面计算的chunk_id来作为uuid。</p>
<p>同时，我们可以使用<code>get</code>方法，来从当前的数据库中检索数据。参数如下：</p>
<ul>
<li>ids: 指定要检索的文档的唯一 ID 列表。</li>
<li>where: 通过元数据字段进行过滤的条件。</li>
<li>include: 指定返回的数据字段，例如 [“documents”, “metadatas”]。</li>
</ul>
<h2 id="检索生成"><a href="#检索生成" class="headerlink" title="检索生成"></a>检索生成</h2><h3 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h3><p>通过以上步骤，即可用本地的文件构建一个数据库。下一步就是当用户提出query之后，我们如何在数据库中检索之后，将检索后的答案和prompt嵌入在一起来作为增强，最后输入LLM</p>
<p>其实从代码上来说非常简单，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">results = db.similarity_search_with_score(query_text, k=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">result[<span class="number">0</span>] = (Document(<span class="built_in">id</span>=<span class="string">&#x27;data/monopoly.pdf:0:0&#x27;</span>, metadata=&#123;<span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2007-05-03T12:38:10-04:00&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;Adobe Acrobat 7.0&#x27;</span>, <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;data/monopoly.pdf:0:0&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2007-05-03T12:52:41-04:00&#x27;</span>, <span class="string">&#x27;page&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;Adobe Acrobat 7.0 Paper Capture Plug-in&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;data/monopoly.pdf&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: <span class="number">8</span>&#125;, page_content=<span class="string">&#x27;MONOPOLY....&#x27;</span>), <span class="number">0.6146661206973629</span>)</span><br><span class="line"></span><br><span class="line">result[<span class="number">0</span>][<span class="number">0</span>].__dict__</span><br><span class="line"><span class="comment">## 可以看到document的id属性被赋予了，值就是我们刚刚计算的chunk_id</span></span><br><span class="line">&#123;<span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;data/monopoly.pdf:0:0&#x27;</span>, <span class="string">&#x27;metadata&#x27;</span>: &#123;<span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2007-05-03T12:38:10-04:00&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;Adobe Acrobat 7.0&#x27;</span>, <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;data/monopoly.pdf:0:0&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2007-05-03T12:52:41-04:00&#x27;</span>, <span class="string">&#x27;page&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;Adobe Acrobat 7.0 Paper Capture Plug-in&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;data/monopoly.pdf&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: <span class="number">8</span>&#125;, <span class="string">&#x27;page_content&#x27;</span>: <span class="string">&#x27;MONOPOLY ....&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;Document&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p><code>similarity_search_with_score</code>函数返回一个包含元组的列表，每个元组包含两个元素，(文档对象，相似性分数)，相似性分数表示查询文本与文档之间的相似性，通常是一个介于 0 和 1 之间的值，值越接近 1 表示相似性越高。返回的五个文档的相似性分数是升序的。</p>
<h3 id="检索嵌入"><a href="#检索嵌入" class="headerlink" title="检索嵌入"></a>检索嵌入</h3><p>将检索到的前五个相似的文本的内容整合到一起，添加到用户的prompt中:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">PROMPT_TEMPLATE = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Answer the question based only on the following context:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Answer the question based on the above context: &#123;question&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 将文本连起来，中间用\n\n---\n\n分隔</span></span><br><span class="line">context_text = <span class="string">&quot;\n\n---\n\n&quot;</span>.join([doc.page_content <span class="keyword">for</span> doc, _score <span class="keyword">in</span> results])</span><br><span class="line">prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)</span><br><span class="line">prompt = prompt_template.<span class="built_in">format</span>(context=context_text, question=query_text)</span><br><span class="line"><span class="comment"># print(prompt)</span></span><br><span class="line"></span><br><span class="line">model = OllamaLLM(model=<span class="string">&quot;mistral&quot;</span>)</span><br><span class="line">response_text = model.invoke(prompt)</span><br><span class="line"></span><br><span class="line">sources = [doc.metadata.get(<span class="string">&quot;id&quot;</span>, <span class="literal">None</span>) <span class="keyword">for</span> doc, _score <span class="keyword">in</span> results]</span><br><span class="line">formatted_response = <span class="string">f&quot;Response: <span class="subst">&#123;response_text&#125;</span>\nSources: <span class="subst">&#123;sources&#125;</span>&quot;</span></span><br><span class="line"><span class="built_in">print</span>(formatted_response)</span><br><span class="line"><span class="keyword">return</span> response_text</span><br></pre></td></tr></table></figure>

<p>这里使用本地的ollama中的模型开响应。以上就是一个RAG的大致流程。本文简单学习了chroma的一些基本方法，了解了RAG的大致过程和原理。后续可能会继续学习langchain的智能体构建方法，敬请期待。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/pixegami/rag-tutorial-v2">项目参考地址</a></p>
</article><!-- lincense--><div class="license-wrapper"><p> <span>Author:  </span><a href="http://example.com">武丢丢</a></p><p> <span>Link:  </span><a href="http://example.com/2025/04/07/RAG-langchain/">http://example.com/2025/04/07/RAG-langchain/</a></p><p> <span>Copyright:  </span><span>All articles in this blog are licensed under <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by-nc-nd/3.0">CC BY-NC-SA 3.0</a> unless stating additionally.</span></p></div><div class="post-paginator"><a class="prevSlogan" href="/2025/04/07/transformer-MLP/" title="transformer-MLP"><span>< PreviousPost</span><br><span class="prevTitle">transformer-MLP</span></a><a class="nextSlogan" href="/2025/04/04/transformer-Normalization/" title="transformer-Normalization"><span>NextPost ></span><br><span class="nextTitle">transformer-Normalization</span></a><div class="clear"></div></div><div id="comment"></div></section></article><footer id="cxo-footer-outer"><div id="cxo-footer-inner"><p class="footer-container"><span>Site by </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span> | theme </span><a target="_blank" rel="noopener" href="https://github.com/Longlongyu/hexo-theme-Cxo"><span>Cxo</span></a></p><i class="fa fa-user"> </i><span id="busuanzi_value_site_uv"></span><span> | </span><i class="fa fa-eye"> </i><span id="busuanzi_value_site_pv"></span></div></footer><!-- catelog--><div class="toc-wrapper" style="top: 70vh;"><div class="toc-catalog"><i class="fa fa-list"> </i><span>CATALOG</span></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#RAG%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">RAG学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.1.</span> <span class="toc-text">数据加载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E6%9F%90%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%8A%A0%E8%BD%BD%E6%89%80%E6%9C%89PDF%E6%96%87%E6%A1%A3"><span class="toc-number">1.1.1.</span> <span class="toc-text">从某一个目录下加载所有PDF文档</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E6%8B%86%E5%88%86"><span class="toc-number">1.1.2.</span> <span class="toc-text">文档拆分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BAchunk%E6%B7%BB%E5%8A%A0id"><span class="toc-number">1.1.3.</span> <span class="toc-text">为chunk添加id</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD"><span class="toc-number">1.1.4.</span> <span class="toc-text">添加到向量数据库中</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A3%80%E7%B4%A2%E7%94%9F%E6%88%90"><span class="toc-number">1.2.</span> <span class="toc-text">检索生成</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-number">1.2.1.</span> <span class="toc-text">相似度计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E7%B4%A2%E5%B5%8C%E5%85%A5"><span class="toc-number">1.2.2.</span> <span class="toc-text">检索嵌入</span></a></li></ol></li></ol></li></ol></div><!-- top--><i class="fa fa-arrow-up close" id="go-up" aria-hidden="true"></i></body></html>